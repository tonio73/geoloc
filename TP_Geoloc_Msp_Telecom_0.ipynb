{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from sklearn import linear_model, model_selection, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "df_mess_train = pd.read_csv('mess_train_list.csv')\n",
    "\n",
    "# test set\n",
    "df_mess_test = pd.read_csv('mess_test_list.csv')\n",
    "\n",
    "# position associated to train set\n",
    "pos_train = pd.read_csv('pos_train_list.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mess_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mess_train.shape)\n",
    "df_mess_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine all Base stations that received at least 1 message\n",
    "trainBs  = np.unique(df_mess_train['bsid'])\n",
    "testBs   = np.unique(df_mess_test['bsid'])\n",
    "listOfBs = np.union1d(trainBs, testBs) \n",
    "testOnlyBs = np.lib.arraysetops.setdiff1d(testBs, trainBs)\n",
    "\n",
    "print(f\"Number of stations: %d, test only %d\" % (len(listOfBs), len(testOnlyBs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mess_train['did'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tan_degree(x):\n",
    "    \"\"\" Tangent for degree values (latitude) \"\"\"\n",
    "    return np.tan(x * np.pi / 180)\n",
    "\n",
    "def arctan_degree(x):\n",
    "    \"\"\" arc tan to degree \"\"\"\n",
    "    return np.arctan(x) * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_mat_const(df, listOfBs):\n",
    "    \"\"\" Feature Matrix construction \"\"\"\n",
    "    \n",
    "    # Add active column\n",
    "    df['active'] = 1\n",
    "    \n",
    "    # Add tangent of latitude\n",
    "    df['bs_tanlat'] = tan_degree(df['bs_lat'])\n",
    "    \n",
    "    # Add extra rows for Base-stations that are not present in this dataset\n",
    "    usedBs = np.unique(df['bsid'])\n",
    "    missingBs = np.lib.arraysetops.setdiff1d(listOfBs, usedBs)\n",
    "    df2 = pd.DataFrame([['-1', bs, 0, 0, 0, 0, 0, 0, 0, 0] for bs in missingBs], columns=df.columns)\n",
    "    df = df.append(df2)\n",
    "    \n",
    "    #df = df[df['bs_lat'] < 50]\n",
    "    \n",
    "    # Pivot BS to columns\n",
    "    df = df.pivot_table(index='messid', \n",
    "                                    values=['active', 'nseq', 'rssi', 'bs_tanlat', 'bs_lng'], \n",
    "                                    columns=['bsid'],\n",
    "                                    fill_value=0)\n",
    "    resDf = df.reorder_levels([1, 0], axis=1).sort_index(level=0, axis=1)\n",
    "    return resDf.drop(['-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_const(df_mess_train, pos_train):\n",
    "    \"\"\" Ground truth construction \"\"\"\n",
    "    \n",
    "    df = pd.concat([df_mess_train[['messid']], pos_train], axis=1)\n",
    "    df_mean = df.groupby('messid').mean()\n",
    "\n",
    "    return df_mean['lat'], df_mean['lng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_feat = feat_mat_const(df_mess_train, listOfBs)\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_lat, ground_truth_lng = ground_truth_const(df_mess_train, pos_train)\n",
    "ground_truth_lat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make regressor and prediction using the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_and_predict(df_feat, ground_truth_lat, ground_truth_lng, df_test):\n",
    "    \n",
    "    \"\"\" train regressor and make prediction in the train set\n",
    "      Input: df_feat: feature matrix used to train regressor\n",
    "             ground_truth_lat: df_feat associated latitude\n",
    "             ground_truth_lng: df_feat associated longitude\n",
    "             df_test: data frame used for prediction\n",
    "      Output: y_pred_lat, y_pred_lng\n",
    "    \"\"\"\n",
    "\n",
    "    X_train = np.array(df_feat);\n",
    "    reg = linear_model.LinearRegression()\n",
    "\n",
    "    reg.fit(X_train, np.c_[tan_degree(ground_truth_lat), ground_truth_lng]);\n",
    "    y_pred = reg.predict(df_test) \n",
    "\n",
    "    return arctan_degree(y_pred[:,0]), y_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_lat, y_pred_lng = regressor_and_predict(df_feat, ground_truth_lat, ground_truth_lng, df_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "y_pred = model_selection.cross_val_predict(reg, df_feat, np.c_[tan_degree(ground_truth_lat), ground_truth_lng], cv=5)\n",
    "y_pred_lat = arctan_degree(y_pred[:,0])\n",
    "y_pred_lng = y_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vincenty_vec(vec_coord):\n",
    "    \"\"\" Now using geodesic distance instead of Vincenty \"\"\"\n",
    "    vin_vec_dist = np.zeros(vec_coord.shape[0])\n",
    "    if vec_coord.shape[1] != 4:\n",
    "        print('ERROR: Bad number of columns (shall be = 4)')\n",
    "    else:\n",
    "        vin_vec_dist = [geodesic(vec_coord[m, 0:2], vec_coord[m, 2:]).meters for m in range(vec_coord.shape[0])]\n",
    "\n",
    "    return vin_vec_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate distance error for each predicted point\n",
    "def eval_geoloc(y_train_lat , y_train_lng, y_pred_lat, y_pred_lng):\n",
    "    vec_coord = np.array([y_train_lat , y_train_lng, y_pred_lat, y_pred_lng])\n",
    "    err_vec = vincenty_vec(np.transpose(vec_coord))\n",
    "    \n",
    "    return err_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove asburd values of latitude and longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip latitudes to [-90, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_vec = eval_geoloc(ground_truth_lat, ground_truth_lng, y_pred_lat, y_pred_lng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotError(err_vec):\n",
    "    \n",
    "    print(f\"error @ 80% = {np.percentile(err_vec, 80):.1f} m\")\n",
    "    \n",
    "    values, base = np.histogram(err_vec, bins=50000)\n",
    "    cumulative = np.cumsum(values) \n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(base[:-1]/1000, cumulative / np.float(np.sum(values))  * 100.0,\n",
    "             label=\"Opt LLR\", c='blue')\n",
    "\n",
    "    # plot error @ 80%\n",
    "    plt.axvline(x=np.percentile(err_vec, 80)/1000., ymin=0, ymax=100,\n",
    "                linestyle='dashed', color='red')\n",
    "\n",
    "    plt.xlabel('Distance Error (km)')\n",
    "    plt.ylabel('Cum proba (%)')\n",
    "    plt.axis([0, 30, 0, 100]) \n",
    "\n",
    "    plt.title('Error Cumulative Probability')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotError(err_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(ground_truth_lat, y_pred_lat), \\\n",
    "metrics.mean_squared_error(ground_truth_lng, y_pred_lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 9))\n",
    "axes[0].hist(ground_truth_lat, label='ref', bins=range(-91, 92), density=True)\n",
    "axes[0].hist(y_pred_lat, label='pred', alpha=0.7, bins=range(-91, 92), density=True)\n",
    "axes[0].set_title('Latitude histo')\n",
    "axes[0].grid()\n",
    "axes[1].hist(ground_truth_lng, label='ref', bins=range(-181, 182), density=True)\n",
    "axes[1].hist(y_pred_lng, label='pred', alpha=0.7, bins=range(-181, 182), density=True)\n",
    "axes[1].set_title('Longitude histo')\n",
    "axes[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plausible_lat = (y_pred_lat > -80) & (y_pred_lat < 80)\n",
    "\n",
    "metrics.mean_squared_error(ground_truth_lat[plausible_lat], y_pred_lat[plausible_lat]), plausible_lat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plausible_lng = (y_pred_lng > -180) & (y_pred_lng < 180)\n",
    "\n",
    "metrics.mean_squared_error(ground_truth_lng[plausible_lng], y_pred_lng[plausible_lng]), plausible_lng.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_lat < -85).sum(), (y_pred_lng < -180).sum(), (y_pred_lat > 85).sum(), (y_pred_lng > 180).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plausible_lat ^ plausible_lng).sum(), (plausible_lat & plausible_lng).sum() # XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are the same on latitude and longitude\n",
    "\n",
    "Let's compute the error without the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_vec_plausible = eval_geoloc(ground_truth_lat[plausible_lat], ground_truth_lng[plausible_lat], \n",
    "                            y_pred_lat[plausible_lat], y_pred_lng[plausible_lat])\n",
    "plotError(err_vec_plausible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Construct test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mess_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_test = feat_mat_const(df_mess_test, listOfBs)\n",
    "df_feat.shape, df_feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_lat, y_pred_test_lng = regressor_and_predict(df_feat, ground_truth_lat, ground_truth_lng, df_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = pd.DataFrame(np.array([y_pred_test_lat, y_pred_test_lng]).T, columns = ['lat', 'lng'])\n",
    "test_res = pd.concat([df_mess_test['messid'], test_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res.to_csv('pred_pos_test_list.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
